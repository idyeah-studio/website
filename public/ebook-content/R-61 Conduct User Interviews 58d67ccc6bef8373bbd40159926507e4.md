# R-61: Conduct User Interviews

# Recipe #61: Conduct User Interviews

Category: Bonus ‚Äî User Research  |  ‚è±Ô∏è¬†40-50 min  |  üå∂Ô∏èüå∂Ô∏è¬†Intermediate

<aside>
üéØ

**USE WHEN:**

You need to understand user needs, behaviors, motivations, and pain points through one-on-one conversations - planning research studies, recruiting participants, creating interview guides, conducting interviews, or analyzing qualitative data. Your team is making design decisions without user input, assumptions are untested, or you need deep insights that surveys and analytics can't provide.

</aside>

---

<aside>
‚ö†Ô∏è

**THE CHALLENGE**

Many designers skip user research or do it poorly - designing based on assumptions (what they think users need, not what users actually need), conducting interviews without clear goals (asking random questions, no structured approach), asking leading questions (biasing responses, confirming existing beliefs), talking too much instead of listening (selling ideas instead of learning), recruiting wrong participants (not representative of target users), or failing to analyze findings systematically (anecdotal insights, cherry-picking quotes). Teams build features users don't want, miss critical pain points, make decisions based on opinions not evidence, or conduct interviews that waste participants' time without yielding actionable insights. You need systematic interview research - clear research goals (what you want to learn), proper participant recruitment (screeners, representative sample), structured interview guides (open-ended questions, probes, timing), effective moderation (active listening, digging deeper, staying neutral), thorough documentation (notes, recordings, transcripts), and rigorous analysis (themes, patterns, actionable insights).

</aside>

---

<aside>
üìä

**WHAT TO EXPECT**

The AI will deliver a complete interview research framework: research planning with clear goals and success criteria, participant recruitment with screener questions and incentive guidelines, structured 60-minute interview guide with open-ended questions and probes, interview techniques (active listening, follow-ups, avoiding bias), documentation methods (recording, transcripts, note-taking), analysis approaches (coding themes, affinity mapping, pattern identification), and presentation formats (research reports with quotes, highlight reels, actionable recommendations) - transforming ad-hoc conversations into systematic, rigorous qualitative research that generates evidence-based insights.

</aside>

---

<aside>
üß™

**THE PROMPT BLUEPRINT**

```jsx
Act as a User Research Specialist focusing on qualitative research methods, interview techniques, and insight generation from user conversations.

I'm planning user interviews for [Product/Feature] to understand [Research Goals] by talking to [Target Users] and uncovering insights about [Focus Areas].

[OPTIONAL: Attach current product, research questions, or previous research]

Interview research requirements:
- Research goals: [e.g., Understand pain points in current workflow, Validate feature concept, Explore user needs]
- Target users: [e.g., Project managers in tech companies, E-commerce shoppers, Mobile app users]
- Number of interviews: [e.g., 5-8 participants, 10-12 participants for comprehensive study]
- Interview format: [e.g., 45-60 min remote video calls, 30 min in-person, 20 min quick calls]
- Focus areas: [e.g., Current tools and workflows, Pain points and frustrations, Goals and motivations]

Current research problems:
- [Problem 1: e.g., No research done - team designs based on assumptions, not user input]
- [Problem 2: e.g., Leading questions - "Don't you think this feature would be useful?" biases responses]
- [Problem 3: e.g., Wrong participants - interviewing anyone available, not target users]
- [Problem 4: e.g., Poor notes - relying on memory, missing key insights, no recordings]
- [Problem 5: e.g., No analysis - anecdotal insights, cherry-picking quotes, no systematic themes]

Team context: [Research experience level, timeline, budget, stakeholder buy-in]

Please provide:
1. Research planning (defining goals, research questions, success criteria)
2. Participant recruitment (screener questions, recruitment channels, incentives)
3. Interview guide creation (question types, structure, timing, probes)
4. Interview techniques (active listening, asking follow-ups, avoiding bias, building rapport)
5. Remote vs in-person considerations (tools, recording, technical setup)
6. Documentation methods (note-taking, recording, transcripts, organizing data)
7. Analysis approaches (coding, themes, affinity mapping, patterns)
8. Presenting findings (research reports, highlight reels, actionable insights for stakeholders)

Consider: [Constraints - e.g., Limited time/budget, Remote only, Need quick insights, Stakeholder skepticism]
```

üí° What to customize:

- [Product/Feature] = What you're researching
- [Research Goals] = What you want to learn
- [Target Users] = Who you need to interview
- [Focus Areas] = What to explore
- [Number of interviews] = How many participants
- [Problems 1-5] = Current research issues
- Attach product/feature being researched
</aside>

---

<aside>
‚ú®

**LIVE EXAMPLE**

```jsx
Act as a User Research Specialist focusing on qualitative research methods, interview techniques, and insight generation from user conversations.

I'm planning user interviews for a SaaS Project Management Tool's new "AI Task Assistant" feature to understand current task management pain points and validate the AI assistant concept by talking to project managers and team leads and uncovering insights about their workflows, frustrations, and AI expectations.

[User would attach current product screenshots, AI assistant concept mockups]

Interview research requirements:
- Research goals:
  - Understand current task management workflows (what tools, what steps, what's manual)
  - Identify pain points and frustrations (where do things break down, what takes too long)
  - Validate AI assistant concept (does it solve real problems, would they use it, concerns)
  - Explore AI expectations and concerns (what AI should/shouldn't do, trust issues, accuracy needs)
  - Discover feature priorities (what features most valuable, what's nice-to-have)
- Target users:
  - Project managers (manage 2-5 projects, 5-20 team members)
  - Team leads (technical leads, design leads, manage smaller teams)
  - Industry: Tech companies, agencies, startups (B2B SaaS users)
  - Experience: Currently using project management tools (Asana, Jira, Monday, ClickUp)
  - Not: Individual contributors, executives (different needs)
- Number of interviews:
  - 8-10 participants (enough for pattern saturation)
  - Mix: 5-6 project managers, 3-4 team leads
  - Diverse: Different company sizes, industries within tech
- Interview format:
  - 60 minutes remote video calls (Zoom)
  - Screen sharing: Show current tools and workflows
  - Concept validation: Show AI assistant mockup (last 15 min)
  - Recorded: With consent for later analysis
- Focus areas:
  - Current workflows: How they manage tasks today (tools, processes, pain points)
  - Task creation: How tasks are created, assigned, prioritized, tracked
  - Communication: How task updates are communicated (Slack, email, comments)
  - Time spent: What takes the most time, what's repetitive/manual
  - AI perceptions: What AI could help with, concerns about AI accuracy/control

Current research problems:
- No user research done previously - Team designed AI assistant based on assumptions about what users want, haven't validated with actual users, high risk of building wrong thing
- Stakeholders want leading questions - "Wouldn't an AI assistant save you time?" confirms bias instead of discovering truth, need neutral questions that uncover real needs
- Unclear who to interview - Team wants to "interview anyone who manages tasks" too broad, need specific screener for project managers actively using PM tools
- No interview structure - Previous attempts were unstructured conversations, went off-topic, missed key questions, ran out of time, inconsistent across participants
- Poor documentation - Previous interviews relied on memory and quick notes, missed important quotes, couldn't remember details later, no recordings (consent issues)
- Anecdotal analysis - After previous research, team cherry-picked quotes that confirmed their ideas, ignored contrary evidence, no systematic theme identification

Team context:
- Research experience: Limited (1 designer has done interviews before, others new to research)
- Timeline: 3 weeks (recruit week 1, interview week 2-3, analyze/present week 3)
- Budget: $500 for incentives ($50-75 per participant)
- Stakeholders: Product manager skeptical of research ("we already know what users want"), need compelling findings
- Goal: Validate AI assistant concept OR identify different direction if concept doesn't resonate

Please provide:
1. Research planning (defining goals, research questions, success criteria)
2. Participant recruitment (screener questions, recruitment channels, incentives)
3. Interview guide creation (question types, structure, timing, probes)
4. Interview techniques (active listening, asking follow-ups, avoiding bias, building rapport)
5. Remote vs in-person considerations (tools, recording, technical setup)
6. Documentation methods (note-taking, recording, transcripts, organizing data)
7. Analysis approaches (coding, themes, affinity mapping, patterns)
8. Presenting findings (research reports, highlight reels, actionable insights for stakeholders)

Consider: Limited research experience on team. Skeptical stakeholders (need strong evidence). Remote interviews (Zoom). 60-min sessions. 8-10 participants. $50-75 incentives. Need actionable insights in 3 weeks. Validate concept OR pivot direction.
```

</aside>

---

<aside>
üë©‚Äçüç≥

**CHEF'S TIPS**

‚ú¶ Listen 80%, talk 20%: Your job is to learn, not to sell or explain - let participants do most of the talking
‚ú¶ Common mistake: Leading questions like "Don't you think X would be useful?" - instead ask open "How would you use X?"
‚ú¶ Best with: Claude (excellent at creating interview guides, screeners, analysis frameworks), ChatGPT (good for follow-up probes)
‚ú¶ Remix it: "Create interview guide for [product] targeting [users] to understand [pain points/workflows/needs]"
‚ú¶ Pro move: Ask "Analyze my interview transcripts - identify themes, patterns, and actionable insights"

</aside>

---

<aside>
üéØ

**FOLLOW-UP PROMPTS**

- "Create screener questions to recruit project managers who use Asana/Jira with 5+ team members"
- "Write 60-minute interview guide to understand task management workflows and pain points"
- "Analyze these 8 interview transcripts - identify themes, patterns, top pain points, and recommendations"
- "Create research report presenting findings from user interviews with executive summary and quotes"
</aside>

---

<aside>
üíé

**EXAMPLE OUTPUT**

![61_Example_Output.png](61_Example_Output.png)

</aside>

---

<aside>
üîó

**RELATED RECIPES**

‚Üí Recipe #62: [Plan and Run Usability Tests](R-62%20Plan%20and%20Run%20Usability%20Tests%2037867ccc6bef83a9aefe011022174a00.md)
‚Üí Recipe #63: [Research Surveys and Screeners](R-63%20Research%20Surveys%20and%20Screeners%2075767ccc6bef8338adab01eca04d1e57.md)
‚Üí Recipe #07: [Find Hidden User Dead-Ends](R-07%20Find%20Hidden%20User%20Dead-Ends%202d667ccc6bef806b890bc2048285b3fa.md)

</aside>